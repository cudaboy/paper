import streamlit as st
import torch
import torch.nn as nn
import torch.optim as optim
from torchinfo import summary

# --- ëª¨ë“ˆ ì„í¬íŠ¸ ---
# í•„ìš”í•œ ì‚¬ìš©ì ì •ì˜ ëª¨ë“ˆì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
import data_handler  # ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
import model_trainer # ëª¨ë¸ ë¹Œë“œ, í•™ìŠµ, í‰ê°€
import plot_utils    # ê²°ê³¼ ì‹œê°í™”
from utils import set_seed # ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •

def run(params):
    """
    ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë©”ì¸ ë¡œì§ì„ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    ì‚¬ì´ë“œë°”ì—ì„œ ë°›ì€ `params`ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„° ë¡œë”©, ëª¨ë¸ í•™ìŠµ, ê²°ê³¼ í‘œì‹œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    st.title("Train Your Own VGG Model ğŸ§ ")
    st.markdown("---")

    # --- ì´ˆê¸° í™”ë©´ ---
    # í•™ìŠµì´ ì‹œì‘ë˜ê¸° ì „ ì‚¬ìš©ìì—ê²Œ ì•ˆë‚´ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
    if not params["start_button"] and not st.session_state.training_started:
        st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •ì„ ì™„ë£Œí•˜ê³  'í•™ìŠµ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

    # --- í•™ìŠµ ì‹œì‘ ---
    # 'í•™ìŠµ ì‹œì‘' ë²„íŠ¼ì´ í´ë¦­ë˜ë©´ ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    if params["start_button"]:
        # ì„¸ì…˜ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•˜ì—¬ ìƒˆë¡œìš´ í•™ìŠµì„ ì¤€ë¹„í•©ë‹ˆë‹¤.
        st.session_state.training_started = True
        st.session_state.history = {}
        st.session_state.final_results = {}

        # ì¬í˜„ì„±ì„ ìœ„í•´ ëœë¤ ì‹œë“œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
        set_seed(params["random_state"])

        # --- ë°ì´í„° ë¡œë”© ---
        # ìŠ¤í”¼ë„ˆ(spinner)ë¥¼ í‘œì‹œí•˜ì—¬ ë°ì´í„° ì²˜ë¦¬ ì¤‘ì„ì„ ì•Œë¦½ë‹ˆë‹¤.
        with st.spinner("ë°ì´í„° ì²˜ë¦¬ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
            train_loader, val_loader, num_classes = data_handler.create_dataloaders(
                uploaded_file=params["uploaded_file"],
                upload_dir='uploads',
                batch_size=params["batch_size"],
                subset_ratio=params["subset_ratio"],
                random_state=params["random_state"],
                normalize_option=params["normalize_option"]
            )

        # ë°ì´í„° ë¡œë” ìƒì„±ì— ì‹¤íŒ¨í•˜ë©´ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•˜ê³  ì¤‘ë‹¨í•©ë‹ˆë‹¤.
        if train_loader is None:
            st.error("ë°ì´í„° ë¡œë” ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. zip íŒŒì¼ êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            st.stop()

        # --- ëª¨ë¸ ë° ìµœì í™” ì„¤ì • ---
        # ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° CUDA ì¥ì¹˜ë¥¼ ì‚¬ìš©í•˜ê³ , ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        # ì„ íƒëœ VGG ëª¨ë¸ì„ ë¹Œë“œí•˜ê³  ì¥ì¹˜ë¡œ ì´ë™í•©ë‹ˆë‹¤.
        model = model_trainer.build_vgg_model(
            params["model_name"], num_classes, params["use_batch_norm"]
        ).to(device)

        # ì„ íƒëœ ì˜µí‹°ë§ˆì´ì €ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
        if params["optimizer_name"] == "SGD":
            optimizer = optim.SGD(
                model.parameters(),
                lr=params["learning_rate"],
                momentum=params["momentum"],
                weight_decay=params["weight_decay"],
            )
        elif params["optimizer_name"] == "Adam":
            optimizer = optim.Adam(
                model.parameters(), lr=params["learning_rate"], weight_decay=params["weight_decay"]
            )
        else:  # Adagrad
            optimizer = optim.Adagrad(
                model.parameters(), lr=params["learning_rate"], weight_decay=params["weight_decay"]
            )

        # ì†ì‹¤ í•¨ìˆ˜(CrossEntropyLoss)ì™€ ìŠ¤ì¼€ì¤„ëŸ¬(ReduceLROnPlateau)ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
        criterion = nn.CrossEntropyLoss()
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='max', factor=0.1, patience=3 # ê²€ì¦ ì •í™•ë„ê°€ 3 epoch ë™ì•ˆ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ í•™ìŠµë¥ ì„ 0.1ë°°ë¡œ ì¤„ì…ë‹ˆë‹¤.
        )

        st.header("ğŸ“Š í•™ìŠµ ê³¼ì •")

        # --- ëª¨ë¸ ìš”ì•½ ì •ë³´ í‘œì‹œ ---
        st.subheader("Model Summary")
        with st.expander("ëª¨ë¸ êµ¬ì¡° ë³´ê¸°"):
            st.code(f"Device: {device}")
            st.code(
                f"Selected Model: {params['model_name'].upper()} {'with Batch Norm' if params['use_batch_norm'] else ''}"
            )
            st.code(f"Number of Classes: {num_classes}")
            # torchinfo.summaryë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
            model_summary = summary(
                model, input_size=(params["batch_size"], 3, 224, 224), verbose=0
            )
            st.text(str(model_summary))

        # --- í•™ìŠµ ë£¨í”„ ---
        # í•™ìŠµ ë° ê²€ì¦ ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}

        # Streamlit UI ìš”ì†Œë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        epoch_progress_bar = st.progress(0)
        graph_container = st.empty()
        results_container = st.empty()

        for epoch in range(params["epochs"]):
            # í˜„ì¬ ì—í¬í¬ ì§„í–‰ ìƒí™©ì„ í‘œì‹œí•©ë‹ˆë‹¤.
            epoch_progress_bar.progress((epoch + 1) / params["epochs"], text=f"Epoch {epoch + 1}/{params['epochs']}")

            # --- 1 ì—í¬í¬ í•™ìŠµ ë° í‰ê°€ ---
            train_progress_bar = st.progress(0)
            train_loss, train_acc = model_trainer.train_one_epoch(
                model, train_loader, optimizer, criterion, device, train_progress_bar
            )
            train_progress_bar.empty()

            val_progress_bar = st.progress(0)
            val_loss, val_acc = model_trainer.evaluate(
                model, val_loader, criterion, device, val_progress_bar
            )
            val_progress_bar.empty()

            # ê²°ê³¼ë¥¼ í…ì„œì—ì„œ ìŠ¤ì¹¼ë¼ ê°’ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
            train_loss = train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss
            train_acc = train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc
            val_loss = val_loss.item() if isinstance(val_loss, torch.Tensor) else val_loss
            val_acc = val_acc.item() if isinstance(val_acc, torch.Tensor) else val_acc

            # ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
            scheduler.step(val_acc)

            # --- ê²°ê³¼ ê¸°ë¡ ë° ì‹œê°í™” ---
            # í˜„ì¬ ì—í¬í¬ì˜ ê²°ê³¼ë¥¼ historyì— ì¶”ê°€í•©ë‹ˆë‹¤.
            history['train_loss'].append(train_loss)
            history['train_acc'].append(train_acc)
            history['val_loss'].append(val_loss)
            history['val_acc'].append(val_acc)

            # ì„¸ì…˜ ìƒíƒœì— historyë¥¼ ì €ì¥í•˜ì—¬ í˜ì´ì§€ê°€ ë‹¤ì‹œ ë¡œë“œë˜ì–´ë„ ìœ ì§€ë˜ë„ë¡ í•©ë‹ˆë‹¤.
            st.session_state.history = history

            # ì‹¤ì‹œê°„ ê·¸ë˜í”„ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
            with graph_container:
                st.subheader("ì‹¤ì‹œê°„ í•™ìŠµ í˜„í™©")
                plot_utils.plot_history(history)

            # ì—í¬í¬ë³„ ê²°ê³¼ í…Œì´ë¸”ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
            with results_container.container():
                st.subheader("Epoch ë³„ ê²°ê³¼")
                df_results = {
                    'Epoch': list(range(1, epoch + 2)),
                    'Train Loss': [f"{l:.4f}" for l in history['train_loss']],
                    'Train Acc': [f"{a:.2f}%" for a in history['train_acc']],
                    'Val Loss': [f"{l:.4f}" for l in history['val_loss']],
                    'Val Acc': [f"{a:.2f}%" for a in history['val_acc']],
                }
                st.dataframe(df_results, use_container_width=True)

        st.success("ğŸ‰ ëª¨ë“  í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

        # --- ìµœì¢… ê²°ê³¼ ì €ì¥ ---
        # ê°€ì¥ ë†’ì€ ê²€ì¦ ì •í™•ë„ë¥¼ ê¸°ë¡í•œ ì—í¬í¬ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        best_val_acc = max(history['val_acc'])
        best_epoch = history['val_acc'].index(best_val_acc) + 1
        # ì„¸ì…˜ ìƒíƒœì— ìµœì¢… ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
        st.session_state.final_results = {
            'best_val_acc': best_val_acc,
            'best_epoch': best_epoch,
            'final_train_acc': history['train_acc'][-1],
            'final_train_loss': history['train_loss'][-1],
            'final_val_acc': history['val_acc'][-1],
            'final_val_loss': history['val_loss'][-1],
        }

    # --- í•™ìŠµ ì™„ë£Œ í›„ ìµœì¢… ê²°ê³¼ í‘œì‹œ ---
    # ì„¸ì…˜ ìƒíƒœì— ìµœì¢… ê²°ê³¼ê°€ ì €ì¥ë˜ì–´ ìˆëŠ” ê²½ìš°, ìš”ì•½ ì •ë³´ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
    if st.session_state.training_started and st.session_state.final_results:
        st.header("ğŸ ìµœì¢… ê²°ê³¼ ìš”ì•½")

        results = st.session_state.final_results
        # ê°€ì¥ ë†’ì€ ê²€ì¦ ì •í™•ë„ë¥¼ ë©”íŠ¸ë¦­ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
        st.metric(
            label=f"ìµœê³  ê²€ì¦ ì •í™•ë„ (Epoch {results['best_epoch']})",
            value=f"{results['best_val_acc']:.2f}%"
        )

        # ìµœì¢… í•™ìŠµ ë° ê²€ì¦ ê²°ê³¼ë¥¼ ë‘ ê°œì˜ ì—´ë¡œ ë‚˜ëˆ„ì–´ í‘œì‹œí•©ë‹ˆë‹¤.
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ìµœì¢… í•™ìŠµ ê²°ê³¼")
            st.write(f"**Loss:** {results['final_train_loss']:.4f}")
            st.write(f"**Accuracy:** {results['final_train_acc']:.2f}%")
        with col2:
            st.subheader("ìµœì¢… ê²€ì¦ ê²°ê³¼")
            st.write(f"**Loss:** {results['final_val_loss']:.4f}")
            st.write(f"**Accuracy:** {results['final_val_acc']:.2f}%")

        # ìµœì¢… í•™ìŠµ ê·¸ë˜í”„ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
        st.header("ğŸ“ˆ ìµœì¢… í•™ìŠµ ê·¸ë˜í”„")
        plot_utils.plot_history(st.session_state.history)