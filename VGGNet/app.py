import os
import random
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import streamlit as st
from torchinfo import summary

# --- ëª¨ë“ˆ ì„í¬íŠ¸ ---
import data_handler
import model_trainer
import plot_utils

def set_seed(seed):
    """ì¬í˜„ì„±ì„ ìœ„í•´ ì‹œë“œë¥¼ ê³ ì •í•˜ëŠ” í•¨ìˆ˜"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
        # ì•„ë˜ ì£¼ì„ ì²˜ë¦¬ëœ ì˜µì…˜ì€ ì¬í˜„ì„±ì„ ë³´ì¥í•˜ì§€ë§Œ, í•™ìŠµ ì†ë„ë¥¼ ì €í•˜ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # torch.backends.cudnn.deterministic = True
        # torch.backends.cudnn.benchmark = False

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="VGG Model Trainer", layout="wide")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
# í•™ìŠµ ê³¼ì •ê³¼ ê²°ê³¼ë¥¼ ì €ì¥í•˜ì—¬ í˜ì´ì§€ ë¦¬ë¡œë“œ ì‹œì—ë„ ìœ ì§€
if 'training_started' not in st.session_state:
    st.session_state.training_started = False
if 'history' not in st.session_state:
    st.session_state.history = {}
if 'final_results' not in st.session_state:
    st.session_state.final_results = {}

# --- ì‚¬ì´ë“œë°” UI ---
st.sidebar.title("VGG Model Training")
st.sidebar.markdown("---")

# 1. ë°ì´í„° ì—…ë¡œë“œ
st.sidebar.header("Step 1: ë°ì´í„°ì…‹ ì—…ë¡œë“œ")
uploaded_file = st.sidebar.file_uploader(
    "ë°ì´í„°ì…‹ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. (zip, tar.gz, pkl)", 
    type=['zip', 'tar.gz', 'pkl', 'pickle']
)
st.sidebar.info(
    """**zip íŒŒì¼ êµ¬ì¡° ì˜ˆì‹œ:**
```
my_dataset.zip
â””â”€â”€ my_dataset/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ class_A/
    â”‚   â””â”€â”€ class_B/
    â””â”€â”€ val/
        â”œâ”€â”€ class_A/
        â””â”€â”€ class_B/
```"""
)

# 2. ëª¨ë¸ ë° íŒŒë¼ë¯¸í„° ì„ íƒ
st.sidebar.header("Step 2: ëª¨ë¸ ë° í•™ìŠµ ì„¤ì •")
model_name = st.sidebar.selectbox("VGG ëª¨ë¸ ì„ íƒ", list(model_trainer.cfgs.keys()))
use_batch_norm = st.sidebar.checkbox("ë°°ì¹˜ ì •ê·œí™”(Batch Normalization) ì‚¬ìš©", value=True)

st.sidebar.subheader("ë°ì´í„° ì²˜ë¦¬ ì„¤ì •")
normalize_option_label = st.sidebar.radio(
    "ë°ì´í„° ì •ê·œí™”(Normalization) ë°©ì‹",
    ['ImageNet í†µê³„ ì‚¬ìš©', 'ì—…ë¡œë“œí•œ ë°ì´í„°ì…‹ í†µê³„ ì‚¬ìš©'],
    help="ImageNet í†µê³„ëŠ” ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì— ì´ìƒì ì´ë©°, ë°ì´í„°ì…‹ í†µê³„ëŠ” ë°ì´í„°ì…‹ ê³ ìœ ì˜ ë¶„í¬ë¥¼ í•™ìŠµí•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤."
)
normalize_option = 'imagenet' if normalize_option_label == 'ImageNet í†µê³„ ì‚¬ìš©' else 'dataset'

subset_ratio = st.sidebar.slider("ì‚¬ìš©í•  ë°ì´í„° ë¹„ìœ¨", min_value=0.1, max_value=1.0, value=1.0, step=0.1, help="í•™ìŠµ ë° ê²€ì¦ì— ì‚¬ìš©í•  ë°ì´í„°ì˜ ë¹„ìœ¨ì„ ì¡°ì ˆí•©ë‹ˆë‹¤. 1.0ì€ ì „ì²´ ë°ì´í„°ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.")
random_state = st.sidebar.number_input("Random Seed", value=42, min_value=0, help="ë°ì´í„° ìƒ˜í”Œë§ ë° í•™ìŠµ ê³¼ì •ì˜ ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ê°’ì…ë‹ˆë‹¤.")

# í•˜ì´í¼íŒŒë¼ë¯¸í„°
epochs = st.sidebar.number_input("Epochs", min_value=1, max_value=1000, value=10)
batch_size = st.sidebar.number_input("Batch Size", min_value=1, value=32)

st.sidebar.subheader("Optimizer ì„¤ì •")
optimizer_name = st.sidebar.selectbox("Optimizer", ["SGD", "Adam", "Adagrad"])
learning_rate = st.sidebar.number_input("Learning Rate", value=0.01, format="%.4f")
weight_decay = st.sidebar.number_input("Weight Decay", value=0.0005, format="%.4f", help="L2 í˜ë„í‹°. Adamì˜ ê²½ìš° PyTorch êµ¬í˜„ìƒì˜ ì´ìœ ë¡œ ì‹¤ì œë¡œëŠ” L2 ë””ì¼€ì´ì™€ ë‹¤ë¥´ê²Œ ë™ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

momentum = None
if optimizer_name == "SGD":
    momentum = st.sidebar.number_input("Momentum", value=0.9, format="%.2f")

# 3. í•™ìŠµ ì‹œì‘ ë²„íŠ¼
st.sidebar.markdown("---")
start_button = st.sidebar.button("ğŸš€ í•™ìŠµ ì‹œì‘!", disabled=(uploaded_file is None))

# --- ë©”ì¸ í˜ì´ì§€ UI ---
st.title("Train Your Own VGG Model ğŸ§ ")
st.markdown("---")

if not start_button and not st.session_state.training_started:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •ì„ ì™„ë£Œí•˜ê³  'í•™ìŠµ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

if start_button:
    st.session_state.training_started = True
    st.session_state.history = {}
    st.session_state.final_results = {}
    
    set_seed(random_state) # ì¬í˜„ì„±ì„ ìœ„í•´ ì‹œë“œ ì„¤ì •

    with st.spinner("ë°ì´í„° ì²˜ë¦¬ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
        # ë°ì´í„° í¬ë§·ì— ë§ì¶° ë°ì´í„°ë¡œë” ìƒì„±
        train_loader, val_loader, num_classes = data_handler.create_dataloaders(
            uploaded_file=uploaded_file,
            upload_dir='uploads',
            batch_size=batch_size,
            subset_ratio=subset_ratio,
            random_state=random_state,
            normalize_option=normalize_option
        )

    if train_loader is None:
        st.error("ë°ì´í„° ë¡œë” ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. zip íŒŒì¼ êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
    
    # ëª¨ë¸ ë¹Œë“œ
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model_trainer.build_vgg_model(model_name, num_classes, use_batch_norm).to(device)

    # Optimizer, Loss, Scheduler ì •ì˜
    if optimizer_name == "SGD":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)
    elif optimizer_name == "Adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
    else: # Adagrad
        optimizer = optim.Adagrad(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
        
    criterion = nn.CrossEntropyLoss()
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3)

    # --- í•™ìŠµ ê³¼ì • í‘œì‹œ ---
    st.header("ğŸ“Š í•™ìŠµ ê³¼ì •")
    
    # ëª¨ë¸ êµ¬ì¡° ì •ë³´
    st.subheader("Model Summary")
    with st.expander("ëª¨ë¸ êµ¬ì¡° ë³´ê¸°"):
        st.code(f"Device: {device}")
        st.code(f"Selected Model: {model_name.upper()} {'with Batch Norm' if use_batch_norm else ''}")
        st.code(f"Number of Classes: {num_classes}")
        model_summary = summary(model, input_size=(batch_size, 3, 224, 224), verbose=0)
        st.text(str(model_summary))

    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}
    
    # Epoch ì§„í–‰ë¥  í‘œì‹œ
    epoch_progress_bar = st.progress(0)
    
    # ê·¸ë˜í”„ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•œ ì»¨í…Œì´ë„ˆ
    graph_container = st.empty()
    
    # ê²°ê³¼ ìš”ì•½ì„ ìœ„í•œ ì»¨í…Œì´ë„ˆ
    results_container = st.empty()

    for epoch in range(epochs):
        epoch_progress_bar.progress((epoch + 1) / epochs, text=f"Epoch {epoch + 1}/{epochs}")

        # í•™ìŠµ
        train_progress_bar = st.progress(0)
        train_loss, train_acc = model_trainer.train_one_epoch(model, train_loader, optimizer, criterion, device, train_progress_bar)
        train_progress_bar.empty()
        
        # í‰ê°€
        val_progress_bar = st.progress(0)
        val_loss, val_acc = model_trainer.evaluate(model, val_loader, criterion, device, val_progress_bar)
        val_progress_bar.empty()

        # Tensor ê°’ì„ Python float/intë¡œ ë³€í™˜
        train_loss = train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss
        train_acc = train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc
        val_loss = val_loss.item() if isinstance(val_loss, torch.Tensor) else val_loss
        val_acc = val_acc.item() if isinstance(val_acc, torch.Tensor) else val_acc

        scheduler.step(val_acc)

        # ê²°ê³¼ ê¸°ë¡
        history['train_loss'].append(train_loss)
        history['train_acc'].append(train_acc)
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_acc)
        
        # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
        st.session_state.history = history

        # ì‹¤ì‹œê°„ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸
        with graph_container:
            st.subheader("ì‹¤ì‹œê°„ í•™ìŠµ í˜„í™©")
            plot_utils.plot_history(history)
        
        # ì‹¤ì‹œê°„ ê²°ê³¼ ì—…ë°ì´íŠ¸
        with results_container.container():
            st.subheader("Epoch ë³„ ê²°ê³¼")
            df_results = {
                'Epoch': list(range(1, epoch + 2)),
                'Train Loss': [f"{l:.4f}" for l in history['train_loss']],
                'Train Acc': [f"{a:.2f}%" for a in history['train_acc']],
                'Val Loss': [f"{l:.4f}" for l in history['val_loss']],
                'Val Acc': [f"{a:.2f}%" for a in history['val_acc']],
            }
            st.dataframe(df_results, use_container_width=True)


    st.success("ğŸ‰ ëª¨ë“  í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ìµœì¢… ê²°ê³¼ ì €ì¥
    best_val_acc = max(history['val_acc'])
    best_epoch = history['val_acc'].index(best_val_acc) + 1
    st.session_state.final_results = {
        'best_val_acc': best_val_acc,
        'best_epoch': best_epoch,
        'final_train_acc': history['train_acc'][-1],
        'final_train_loss': history['train_loss'][-1],
        'final_val_acc': history['val_acc'][-1],
        'final_val_loss': history['val_loss'][-1],
    }

# --- í•™ìŠµ ì™„ë£Œ í›„ ê²°ê³¼ í‘œì‹œ ---
if st.session_state.training_started and st.session_state.final_results:
    st.header("ğŸ ìµœì¢… ê²°ê³¼ ìš”ì•½")
    
    results = st.session_state.final_results
    st.metric(
        label=f"ìµœê³  ê²€ì¦ ì •í™•ë„ (Epoch {results['best_epoch']})",
        value=f"{results['best_val_acc']:.2f}%"
    )
    
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ìµœì¢… í•™ìŠµ ê²°ê³¼")
        st.write(f"**Loss:** {results['final_train_loss']:.4f}")
        st.write(f"**Accuracy:** {results['final_train_acc']:.2f}%")
    with col2:
        st.subheader("ìµœì¢… ê²€ì¦ ê²°ê³¼")
        st.write(f"**Loss:** {results['final_val_loss']:.4f}")
        st.write(f"**Accuracy:** {results['final_val_acc']:.2f}%")

    st.header("ğŸ“ˆ ìµœì¢… í•™ìŠµ ê·¸ë˜í”„")
    plot_utils.plot_history(st.session_state.history)
